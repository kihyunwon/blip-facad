{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f66ec4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "trl\n",
    "sagemaker\n",
    "datasets\n",
    "pillow\n",
    "torch==2.4.1\n",
    "peft\n",
    "h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "363da222",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trl in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.12.2)\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.237.0)\n",
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: pillow in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (11.0.0)\n",
      "Collecting torch==2.0.1 (from -r requirements.txt (line 5))\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: peft in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (3.12.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 5)) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 5)) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 5)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 5)) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.0.0 (from torch==2.0.1->-r requirements.txt (line 5))\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 5)) (75.3.0)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 5)) (0.45.0)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 5))\n",
      "  Downloading cmake-3.31.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 5))\n",
      "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trl->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: rich in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trl->-r requirements.txt (line 1)) (13.9.4)\n",
      "Requirement already satisfied: transformers<4.47.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trl->-r requirements.txt (line 1)) (4.46.3)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (23.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.35.75 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (1.35.76)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (0.115.6)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (6.11.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (4.23.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: omegaconf<2.3,>=2.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (1.5.3)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (0.3.2)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (4.3.6)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (4.25.5)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (6.1.0)\n",
      "Requirement already satisfied: pyyaml~=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (1.0.17)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (4.67.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: uvicorn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker->-r requirements.txt (line 2)) (0.32.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (3.11.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (0.26.5)\n",
      "Requirement already satisfied: safetensors in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft->-r requirements.txt (line 6)) (0.4.5)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.76 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.35.75->sagemaker->-r requirements.txt (line 2)) (1.35.76)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.35.75->sagemaker->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.35.75->sagemaker->-r requirements.txt (line 2)) (0.10.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.18.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker->-r requirements.txt (line 2)) (3.21.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from omegaconf<2.3,>=2.2->sagemaker->-r requirements.txt (line 2)) (4.9.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->sagemaker->-r requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker->-r requirements.txt (line 2)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker->-r requirements.txt (line 2)) (2024.8.30)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker->-r requirements.txt (line 2)) (2.9.2)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker->-r requirements.txt (line 2)) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker->-r requirements.txt (line 2)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker->-r requirements.txt (line 2)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker->-r requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich->trl->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich->trl->-r requirements.txt (line 1)) (2.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers<4.47.0->trl->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers<4.47.0->trl->-r requirements.txt (line 1)) (0.20.3)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fastapi->sagemaker->-r requirements.txt (line 2)) (0.41.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-pasta->sagemaker->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch==2.0.1->-r requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker->-r requirements.txt (line 2)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker->-r requirements.txt (line 2)) (1.7.6.9)\n",
      "Requirement already satisfied: pox>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker->-r requirements.txt (line 2)) (0.3.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch==2.0.1->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn->sagemaker->-r requirements.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn->sagemaker->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl->-r requirements.txt (line 1)) (0.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker->-r requirements.txt (line 2)) (2.23.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from starlette<0.42.0,>=0.40.0->fastapi->sagemaker->-r requirements.txt (line 2)) (4.6.2.post1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi->sagemaker->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi->sagemaker->-r requirements.txt (line 2)) (1.2.2)\n",
      "Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m204.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m156.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cmake-3.31.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
      "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "Successfully installed cmake-3.31.1 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "517c4641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "devtmpfs         16G     0   16G   0% /dev\r\n",
      "tmpfs            16G     0   16G   0% /dev/shm\r\n",
      "tmpfs            16G  708K   16G   1% /run\r\n",
      "tmpfs            16G     0   16G   0% /sys/fs/cgroup\r\n",
      "/dev/nvme0n1p1  135G   88G   48G  65% /\r\n",
      "tmpfs           3.1G     0  3.1G   0% /run/user/0\r\n",
      "/dev/nvme2n1    296G  224K  281G   1% /home/ec2-user/SageMaker\r\n",
      "tmpfs           3.1G     0  3.1G   0% /run/user/1002\r\n",
      "tmpfs           3.1G     0  3.1G   0% /run/user/1001\r\n",
      "tmpfs           3.1G     0  3.1G   0% /run/user/1000\r\n"
     ]
    }
   ],
   "source": [
    "!df -h\n",
    "!mkdir /home/ec2-user/SageMaker/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1efb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_bucket = sess.default_bucket()\n",
    "iam = boto3.client('iam')\n",
    "role = iam.get_role(RoleName='AmazonSageMaker-ExecutionRole-20241127T090079')['Role']['Arn']\n",
    "\n",
    "s3_prefix = 'training-data'\n",
    "ec2_data_prefix = '/home/ec2-user/SageMaker/data'\n",
    "base_job_name = \"blip-finetune-facad\"\n",
    "\n",
    "checkpoint_s3_uri = f's3://{sagemaker_bucket}/{base_job_name}/checkpoints'\n",
    "train_image_s3_path = f'{s3_prefix}/train/TRAIN_IMAGES.hdf5'\n",
    "train_caption_s3_path = f'{s3_prefix}/train/TRAIN_CAPTIONS.txt'\n",
    "eval_image_s3_path = f'{s3_prefix}/eval/VAL_IMAGES.hdf5'\n",
    "eval_caption_s3_path = f'{s3_prefix}/eval/VAL_CAPTIONS.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79a45c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# download files from S3 to local SSD\n",
    "s3 = boto3.client('s3')\n",
    "finetuning_data_files = [train_image_s3_path, train_caption_s3_path, eval_image_s3_path, eval_caption_s3_path]\n",
    "\n",
    "for filepath in finetuning_data_files:\n",
    "    filename = filepath.split('/')[-1]\n",
    "    data_file = os.path.join(ec2_data_prefix, filename)\n",
    "    s3.download_file(sagemaker_bucket, filepath, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "636a5c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_CAPTIONS.txt  TRAIN_IMAGES.hdf5  VAL_CAPTIONS.txt  VAL_IMAGES.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/ec2-user/SageMaker/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c0381c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hdf5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hdf5.py\n",
    "import h5py\n",
    "import datasets\n",
    "\n",
    "\n",
    "class HDF5Config(datasets.BuilderConfig):\n",
    "\n",
    "    def __init__(self, key='', **kwargs):\n",
    "        \"\"\"BuilderConfig for HDF5 file.\n",
    "        \"\"\"\n",
    "        # Version history:\n",
    "        # 0.0.1: Initial version.\n",
    "        super(HDF5Config, self).__init__(version=datasets.Version(\"0.0.1\"), **kwargs)\n",
    "        self.key = key\n",
    "\n",
    "\n",
    "class HDF5(datasets.GeneratorBasedBuilder):\n",
    "\n",
    "    BUILDER_CONFIGS = [\n",
    "        HDF5Config(\n",
    "            name=\"keyed_config\",\n",
    "            description=\"HDF5 Dataset Generator iterates values of provided key\",\n",
    "            key=''\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    def _info(self):\n",
    "        return datasets.DatasetInfo(description=self.config.description)\n",
    "\n",
    "    def _split_generators(self, dl_manager):\n",
    "        if not self.config.data_files:\n",
    "            raise ValueError(f\"At least one data file must be specified, but got data_files={self.config.data_files}\")\n",
    "        dl_manager.download_config.extract_on_the_fly = True\n",
    "        data_files = dl_manager.download_and_extract(self.config.data_files)\n",
    "        splits = []\n",
    "        for split_name, files in data_files.items():\n",
    "            splits.append(datasets.SplitGenerator(name=split_name, gen_kwargs={\"files\": files}))\n",
    "        return splits\n",
    "\n",
    "    def _generate_examples(self, files):\n",
    "        key = self.config.key\n",
    "        for file in files:\n",
    "            with h5py.File(file, \"r\", swmr=True) as data:\n",
    "                if not key:\n",
    "                    raise ValueError(f\"A key must be specified, but got key={key}\")\n",
    "                else:\n",
    "                    for idx, value in enumerate(data[key]):\n",
    "                        yield idx, { key: value }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51b68896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting finetune_blip.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile finetune_blip.py\n",
    "import logging\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import trl\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    BlipForConditionalGeneration,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# custome trl.trainer.ConstantLengthDataset\n",
    "class FashionImageCaptioningDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, dataset, size, processor):\n",
    "        self.dataset = dataset\n",
    "        self.size = size\n",
    "        self.processor = processor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        n = len(self.dataset['image'])\n",
    "        m = len(self.dataset['text'])\n",
    "        if n != m:\n",
    "            raise Exception(f'Expects same image and text datasets, but received {n} images and {m} texts.')\n",
    "\n",
    "        for i in range(n):\n",
    "            image_iterator = iter(self.dataset['image'][i])\n",
    "            text_iterator = iter(self.dataset['text'][i])\n",
    "            while True:\n",
    "                try:\n",
    "                    image = next(image_iterator)['images']\n",
    "                    text = next(text_iterator)['text']\n",
    "                    example = self.processor(images=torch.tensor(image, dtype=torch.int), padding=\"max_length\", return_tensors=\"pt\")\n",
    "                    example = {k: v.squeeze() for k, v in example.items()}\n",
    "                    example['labels'] = text\n",
    "                    yield example\n",
    "                except Exception as err:\n",
    "                    logger.warning(f\"Error generating example: {err}\")\n",
    "                    break\n",
    "\n",
    "@dataclass\n",
    "class SFTTrainingArguments:\n",
    "    model_name_or_path: str\n",
    "    train_data_files: str\n",
    "    train_data_size: int = 0\n",
    "    eval_data_files: str = None\n",
    "    eval_data_size: int = 0\n",
    "    freeze_vision_model: bool = False\n",
    "    freeze_text_model: bool = False\n",
    "    load_in_8bit: bool = False\n",
    "    load_in_4bit: bool = False\n",
    "    use_flash_attention_2: bool = False\n",
    "    use_peft: bool = True\n",
    "    peft_target_model: Optional[str] = \"blip-image-captioning-facad\"\n",
    "    peft_target_modules: Optional[list[str]] = None\n",
    "    peft_lora_r: int = 16\n",
    "    peft_lora_alpha: int = 32\n",
    "    peft_lora_dropout: float = 0.05\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.load_in_8bit and self.load_in_4bit:\n",
    "            raise ValueError(\"load_in_8bit and load_in_4bit are mutually exclusive\")\n",
    "        if self.peft_target_model and self.peft_target_modules is None:\n",
    "            if self.peft_target_model == \"blip-image-captioning-facad\":\n",
    "                self.peft_target_modules = [\n",
    "                    \"self.query\",\n",
    "                    \"self.key\",\n",
    "                    \"self.value\",\n",
    "                    \"output.dense\",\n",
    "                    \"self_attn.qkv\",\n",
    "                    \"self_attn.projection\",\n",
    "                    \"mlp.fc1\",\n",
    "                    \"mlp.fc2\",\n",
    "                ]\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"peft_target_model '{self.peft_target_model}' is not supported, \"\n",
    "                    f\"so peft_target_modules is set to None.\"\n",
    "                )\n",
    "\n",
    "    def from_pretrained_kwargs(self, training_args):\n",
    "        kwargs = {}\n",
    "        if self.load_in_8bit:\n",
    "            kwargs = {\"load_in_8bit\": True}\n",
    "        elif self.load_in_4bit:\n",
    "            kwargs = {\n",
    "                \"quantization_config\": BitsAndBytesConfig(\n",
    "                    load_in_4bit=True,\n",
    "                    bnb_4bit_use_double_quant=True,\n",
    "                    bnb_4bit_quant_type=\"nf4\",\n",
    "                    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                )\n",
    "            }\n",
    "        elif training_args.bf16:\n",
    "            kwargs = {\"torch_dtype\": torch.bfloat16}\n",
    "        else:\n",
    "            kwargs = {\"torch_dtype\": torch.float16}\n",
    "        if self.use_flash_attention_2:\n",
    "            kwargs[\"attn_implementation\"] = \"flash_attention_2\"\n",
    "        return kwargs\n",
    "\n",
    "def load_datasets(data_files):\n",
    "    datasets = {'image': [], 'text': []}\n",
    "    for data_file in data_files:\n",
    "        dataset = None\n",
    "        if data_file.endswith('.hdf5'):\n",
    "            dataset = load_dataset(\"hdf5.py\", name=\"keyed_config\", key=\"images\", data_files=data_file, trust_remote_code=True, streaming=True)\n",
    "            datasets['image'].append(dataset['train'])\n",
    "        else:\n",
    "            dataset = load_dataset(\"text\", data_files=data_file, streaming=True)\n",
    "            datasets['text'].append(dataset['train'])\n",
    "    return datasets\n",
    "\n",
    "def main():\n",
    "    parser = HfArgumentParser((TrainingArguments, SFTTrainingArguments))\n",
    "    training_args, sft_training_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        handlers=[logging.StreamHandler(sys.stdout)],\n",
    "    )\n",
    "\n",
    "    log_level = training_args.get_process_log_level()\n",
    "    logger.setLevel(log_level)\n",
    "    logger.info(f\"Training parameters {training_args}\\nSupervised Fine-Tuning parameters {sft_training_args}\")\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(sft_training_args.model_name_or_path)\n",
    "    kwarg = sft_training_args.from_pretrained_kwargs(training_args)\n",
    "    model = BlipForConditionalGeneration.from_pretrained(sft_training_args.model_name_or_path, **kwarg).to(device)\n",
    "\n",
    "    peft_config = None\n",
    "    if sft_training_args.use_peft:\n",
    "        peft_config = LoraConfig(\n",
    "            r=sft_training_args.peft_lora_r,\n",
    "            target_modules=sft_training_args.peft_target_modules,\n",
    "            lora_alpha=sft_training_args.peft_lora_alpha,\n",
    "            lora_dropout=sft_training_args.peft_lora_dropout,\n",
    "            bias=\"none\"\n",
    "        )\n",
    "        model = get_peft_model(model, peft_config)\n",
    "        if training_args.gradient_checkpointing:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            model.gradient_checkpointing_enable()\n",
    "            model.enable_input_require_grads()\n",
    "\n",
    "    def _freeze_params(module):\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    if sft_training_args.freeze_vision_model:\n",
    "        _freeze_params(model.vision_model)\n",
    "\n",
    "    if sft_training_args.freeze_text_model:\n",
    "        _freeze_params(model.text_model)\n",
    "\n",
    "    train_dataset = None\n",
    "    if sft_training_args.train_data_files:\n",
    "        data_files = sft_training_args.train_data_files.split(',')\n",
    "        train_dataset = load_datasets(data_files)\n",
    "        train_dataset = FashionImageCaptioningDataset(train_dataset, sft_training_args.train_data_size, processor)\n",
    "\n",
    "    eval_dataset = None\n",
    "    if sft_training_args.eval_data_files:\n",
    "        data_files = sft_training_args.eval_data_files.split(',')\n",
    "        eval_dataset = load_datasets(data_files)\n",
    "        eval_dataset = FashionImageCaptioningDataset(eval_dataset, sft_training_args.eval_data_size, processor)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=training_args.per_device_train_batch_size, shuffle=False, pin_memory=True)\n",
    "    eval_dataloader = DataLoader(eval_dataset, batch_size=training_args.per_device_eval_batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=training_args.learning_rate, weight_decay=training_args.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9, last_epoch=-1, verbose=False)\n",
    "    num_epochs = int(training_args.num_train_epochs)\n",
    "    patience = 10\n",
    "    min_eval_loss = float(\"inf\")\n",
    "    early_stopping_hook = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for _, batch in zip(tqdm(range(len(train_dataloader)), desc='Training batch: ...'), train_dataloader):\n",
    "            pixel_values = batch.pop('pixel_values').to(device)\n",
    "            texts = batch.pop('labels')\n",
    "            text_inputs = processor.tokenizer(texts, padding=True, return_tensors=\"pt\").to(device)\n",
    "            input_ids = text_inputs.input_ids\n",
    "            attention_mask = text_inputs.attention_mask\n",
    "\n",
    "            outputs = model(input_ids=input_ids,\n",
    "                            pixel_values=pixel_values,\n",
    "                            attention_mask=attention_mask,\n",
    "                            labels=input_ids)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        eval_loss = 0\n",
    "        for _, batch in zip(tqdm(range(len(eval_dataloader)), desc='Validating batch: ...'), eval_dataloader):\n",
    "            pixel_values = batch.pop('pixel_values').to(device)\n",
    "            texts = batch.pop('labels')\n",
    "            text_inputs = processor.tokenizer(texts, padding=True, return_tensors=\"pt\").to(device)\n",
    "            input_ids = text_inputs.input_ids\n",
    "            attention_mask = text_inputs.attention_mask\n",
    "\n",
    "            outputs = model(input_ids=input_ids,\n",
    "                            pixel_values=pixel_values,\n",
    "                            attention_mask=attention_mask,\n",
    "                            labels=input_ids)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "        print(\"Epoch: {} - Training loss: {} - Eval Loss: {} - LR: {}\".format(epoch+1, epoch_loss/len(train_dataloader), eval_loss/len(eval_dataloader), optimizer.param_groups[0][\"lr\"]))\n",
    "        scheduler.step()\n",
    "        if eval_loss < min_eval_loss:\n",
    "            model.save_pretrained(training_args.output_dir, from_pt=True)\n",
    "            min_eval_loss = eval_loss\n",
    "            early_stopping_hook = 0\n",
    "        else:\n",
    "            early_stopping_hook += 1\n",
    "            if early_stopping_hook > patience:\n",
    "                break\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f'using transformers: {transformers.__version__}, trl: {trl.__version__}')\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f2ebd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/ec2-user/SageMaker/model’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir /home/ec2-user/SageMaker/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d97aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using transformers: 4.46.3, trl: 0.12.2\n",
      "Training batch: ...:   0%|                            | 0/25000 [00:00<?, ?it/s]/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "Training batch: ...:   1%|▏               | 272/25000 [04:49<7:18:13,  1.06s/it]"
     ]
    }
   ],
   "source": [
    "!python finetune_blip.py --eval_data_files /home/ec2-user/SageMaker/data/VAL_IMAGES.hdf5,/home/ec2-user/SageMaker/data/VAL_CAPTIONS.txt --eval_data_size 19915 --freeze_vision_model True --learning_rate 1e-05 --model_name_or_path Salesforce/blip-image-captioning-base --num_train_epochs 5 --output_dir /home/ec2-user/SageMaker/model --per_device_eval_batch_size 32 --per_device_train_batch_size 32 --train_data_files /home/ec2-user/SageMaker/data/VAL_IMAGES.hdf5,/home/ec2-user/SageMaker/data/VAL_CAPTIONS.txt --train_data_size 800000 --weight_decay 0.05 --do_train True --do_eval True --gradient_checkpointing True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
